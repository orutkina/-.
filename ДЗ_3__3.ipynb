{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xMSTRCiLkWcJ",
        "TbrheSykrIZK"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orutkina/-./blob/main/%D0%94%D0%97_3__3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas seaborn scikit-learn"
      ],
      "metadata": {
        "id": "nZXJ0Qwlj2aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# МЛ Практика 3: Задача классификации"
      ],
      "metadata": {
        "id": "tGglnDt0hc5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка необходимых библиотек\n",
        "!pip install pandas seaborn scikit-learn matplotlib\n",
        "\n",
        "# Импорт библиотек\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import chi2_contingency\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                           f1_score, roc_auc_score, confusion_matrix,\n",
        "                           classification_report, roc_curve, auc)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Настройка отображения графиков\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "k6mw6ZCZj0Cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 1: Загрузка и предварительный анализ данных"
      ],
      "metadata": {
        "id": "ceWpUlUah-OB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных\n",
        "df = pd.read_csv('Sleep_health_and_lifestyle_dataset.csv')\n",
        "\n",
        "# Первичный анализ данных\n",
        "print(\"=\"*80)\n",
        "print(\"ПЕРВИЧНЫЙ АНАЛИЗ ДАННЫХ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"Размер датасета: {df.shape}\")\n",
        "print(f\"Количество строк: {df.shape[0]}\")\n",
        "print(f\"Количество столбцов: {df.shape[1]}\")\n",
        "\n",
        "print(\"\\nПервые 5 строк данных:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nИнформация о типах данных:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nСтатистическое описание числовых признаков:\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\nСтатистическое описание категориальных признаков:\")\n",
        "print(df.describe(include=['object', 'category']))\n",
        "\n",
        "print(\"\\nПроверка на пропущенные значения:\")\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values[missing_values > 0])\n",
        "\n",
        "# Проверим уникальные значения в каждом столбце\n",
        "print(\"\\nКоличество уникальных значений в каждом столбце:\")\n",
        "for col in df.columns:\n",
        "    unique_vals = df[col].nunique()\n",
        "    print(f\"{col}: {unique_vals} уникальных значений\")\n",
        "\n",
        "    if unique_vals <= 10:\n",
        "        print(f\"  Значения: {df[col].unique()}\")"
      ],
      "metadata": {
        "id": "7HuuZWm1j-da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 2: Выбор целевой переменной и EDA"
      ],
      "metadata": {
        "id": "naxH9EWHipQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ВЫБОР ЦЕЛЕВОЙ ПЕРЕМЕННОЙ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Выберем категориальную переменную в качестве целевой\n",
        "# В датасете есть несколько категориальных переменных:\n",
        "# 1. Gender (Мужчина/Женщина) - 2 класса\n",
        "# 2. BMI Category (Категория ИМТ) - 3-4 класса\n",
        "# 3. Sleep Disorder (Расстройство сна) - 3 класса\n",
        "# 4. Occupation (Профессия) - много классов\n",
        "\n",
        "# Для задачи классификации выберем 'Sleep Disorder' как целевую переменную\n",
        "# Это интересная медицинская задача с тремя классами\n",
        "print(\"Выбрана целевая переменная: 'Sleep Disorder' (Расстройство сна)\")\n",
        "print(f\"Распределение классов:\")\n",
        "print(df['Sleep Disorder'].value_counts())\n",
        "print(f\"\\nПроцентное распределение:\")\n",
        "print(df['Sleep Disorder'].value_counts(normalize=True) * 100)\n",
        "\n",
        "# Преобразуем целевую переменную\n",
        "y = df['Sleep Disorder']\n",
        "\n",
        "# Создадим бинарную версию для некоторых анализов\n",
        "# Объединим 'Sleep Apnea' и 'Insomnia' в один класс 'Has Disorder'\n",
        "y_binary = y.copy()\n",
        "y_binary = y_binary.apply(lambda x: 'No Disorder' if x == 'None' else 'Has Disorder')\n",
        "print(f\"\\nБинарная версия (для некоторых анализов):\")\n",
        "print(y_binary.value_counts())"
      ],
      "metadata": {
        "id": "gvGp1Rf4lgPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 3: Разведочный анализ данных (EDA)"
      ],
      "metadata": {
        "id": "xMSTRCiLkWcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"РАЗВЕДОЧНЫЙ АНАЛИЗ ДАННЫХ (EDA)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Создадим копию данных для анализа\n",
        "df_eda = df.copy()\n",
        "\n",
        "# 1. Распределение целевой переменной\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Круговая диаграмма\n",
        "class_counts = df_eda['Sleep Disorder'].value_counts()\n",
        "axes[0].pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%',\n",
        "           colors=['#4CAF50', '#2196F3', '#FF9800'])\n",
        "axes[0].set_title('Распределение расстройств сна')\n",
        "\n",
        "# Столбчатая диаграмма\n",
        "axes[1].bar(class_counts.index, class_counts.values, color=['#4CAF50', '#2196F3', '#FF9800'])\n",
        "axes[1].set_xlabel('Тип расстройства сна')\n",
        "axes[1].set_ylabel('Количество')\n",
        "axes[1].set_title('Количество наблюдений по типам расстройств')\n",
        "for i, v in enumerate(class_counts.values):\n",
        "    axes[1].text(i, v + 3, str(v), ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 2. Анализ числовых признаков относительно целевой переменной\n",
        "print(\"\\nАНАЛИЗ ЧИСЛОВЫХ ПРИЗНАКОВ:\")\n",
        "\n",
        "# Выделим числовые признаки\n",
        "numeric_cols = df_eda.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(f\"Числовые признаки: {numeric_cols}\")\n",
        "\n",
        "# Создадим графики для анализа числовых признаков\n",
        "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(numeric_cols[:9]):\n",
        "    # Boxplot по классам\n",
        "    data_to_plot = [df_eda[df_eda['Sleep Disorder'] == cls][col] for cls in df_eda['Sleep Disorder'].unique()]\n",
        "    axes[i].boxplot(data_to_plot, labels=df_eda['Sleep Disorder'].unique())\n",
        "    axes[i].set_title(f'{col} по типам расстройств')\n",
        "    axes[i].set_xlabel('Тип расстройства')\n",
        "    axes[i].set_ylabel(col)\n",
        "    axes[i].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Удалим лишние оси\n",
        "for i in range(len(numeric_cols[:9]), len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3. Анализ категориальных признаков относительно целевой переменной\n",
        "print(\"\\nАНАЛИЗ КАТЕГОРИАЛЬНЫХ ПРИЗНАКОВ:\")\n",
        "\n",
        "categorical_cols = ['Gender', 'Occupation', 'BMI Category']\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "for i, col in enumerate(categorical_cols):\n",
        "    # Crosstab и heatmap\n",
        "    crosstab = pd.crosstab(df_eda[col], df_eda['Sleep Disorder'], normalize='index')\n",
        "    sns.heatmap(crosstab, annot=True, fmt='.2f', cmap='YlOrRd', ax=axes[i])\n",
        "    axes[i].set_title(f'{col} vs Расстройство сна')\n",
        "    axes[i].set_xlabel('Расстройство сна')\n",
        "    axes[i].set_ylabel(col)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 4. Анализ зависимости между категориальными переменными (тест хи-квадрат)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"АНАЛИЗ ЗАВИСИМОСТИ МЕЖДУ КАТЕГОРИАЛЬНЫМИ ПЕРЕМЕННЫМИ (ТЕСТ ХИ-КВАДРАТ)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Создадим таблицу сопряженности для категориальных признаков\n",
        "categorical_features = ['Gender', 'Occupation', 'BMI Category', 'Sleep Disorder']\n",
        "\n",
        "print(\"Результаты теста хи-квадрат для пар категориальных признаков:\\n\")\n",
        "print(\"{:<20} {:<20} {:<15} {:<15} {:<15}\".format(\n",
        "    \"Признак 1\", \"Признак 2\", \"Хи-квадрат\", \"p-value\", \"Зависимость\"\n",
        "))\n",
        "print(\"-\" * 85)\n",
        "\n",
        "for i in range(len(categorical_features)):\n",
        "    for j in range(i+1, len(categorical_features)):\n",
        "        col1 = categorical_features[i]\n",
        "        col2 = categorical_features[j]\n",
        "\n",
        "        # Создаем таблицу сопряженности\n",
        "        contingency_table = pd.crosstab(df_eda[col1], df_eda[col2])\n",
        "\n",
        "        # Проводим тест хи-квадрат\n",
        "        chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "        # Определяем наличие зависимости\n",
        "        dependence = \"Есть\" if p < 0.05 else \"Нет\"\n",
        "\n",
        "        print(\"{:<20} {:<20} {:<15.2f} {:<15.4f} {:<15}\".format(\n",
        "            col1, col2, chi2, p, dependence\n",
        "        ))\n",
        "\n",
        "# 5. Корреляционный анализ\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"КОРРЕЛЯЦИОННЫЙ АНАЛИЗ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Создадим корреляционную матрицу для числовых признаков\n",
        "correlation_matrix = df_eda[numeric_cols].corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm',\n",
        "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Корреляционная матрица числовых признаков')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Анализируем корреляции с целевой переменной (предварительно закодировав ее)\n",
        "print(\"\\nКорреляция числовых признаков с целевой переменной (после Label Encoding):\")\n",
        "\n",
        "# Создадим копию данных для кодирования\n",
        "df_corr = df_eda.copy()\n",
        "le = LabelEncoder()\n",
        "df_corr['Sleep Disorder_encoded'] = le.fit_transform(df_corr['Sleep Disorder'])\n",
        "\n",
        "# Рассчитаем корреляции\n",
        "correlations = {}\n",
        "for col in numeric_cols:\n",
        "    corr = df_corr[col].corr(df_corr['Sleep Disorder_encoded'])\n",
        "    correlations[col] = corr\n",
        "\n",
        "# Сортируем по абсолютному значению корреляции\n",
        "sorted_correlations = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "print(\"\\n{:<25} {:<15}\".format(\"Признак\", \"Корреляция\"))\n",
        "print(\"-\" * 40)\n",
        "for col, corr in sorted_correlations:\n",
        "    print(\"{:<25} {:<15.4f}\".format(col, corr))"
      ],
      "metadata": {
        "id": "seqFKG06y4XE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 4: Отбор признаков (Feature Selection)"
      ],
      "metadata": {
        "id": "2E12Z-KnneJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ОТБОР ПРИЗНАКОВ ДЛЯ МОДЕЛИ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# На основе EDA выбираем лучшие признаки\n",
        "# Критерии отбора:\n",
        "# 1. Высокая корреляция с целевой переменной\n",
        "# 2. Информативность (хи-квадрат тест)\n",
        "# 3. Отсутствие мультиколлинеарности\n",
        "\n",
        "# Выберем следующие признаки:\n",
        "best_features = [\n",
        "    'Age',                    # Высокая корреляция с расстройством сна\n",
        "    'Physical Activity Level', # Важный фактор для сна\n",
        "    'Stress Level',           # Прямо влияет на качество сна\n",
        "    'Heart Rate',             # Медицинский показатель\n",
        "    'Daily Steps',            # Активность в течение дня\n",
        "    'BMI Category',           # Категориальный признак, показавший зависимость\n",
        "    'Occupation'              # Профессия влияет на режим сна\n",
        "]\n",
        "\n",
        "print(f\"Выбрано {len(best_features)} признаков для модели:\")\n",
        "for i, feature in enumerate(best_features, 1):\n",
        "    print(f\"{i}. {feature}\")\n",
        "\n",
        "# Проверим распределение выбранных признаков\n",
        "print(\"\\nРаспределение значений в выбранных признаках:\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, feature in enumerate(best_features[:7]):\n",
        "    if df_eda[feature].dtype in [np.int64, np.float64]:\n",
        "        # Для числовых признаков - гистограмма\n",
        "        axes[i].hist(df_eda[feature], bins=20, edgecolor='black', alpha=0.7)\n",
        "        axes[i].set_title(feature)\n",
        "        axes[i].set_xlabel('Значение')\n",
        "        axes[i].set_ylabel('Частота')\n",
        "    else:\n",
        "        # Для категориальных признаков - bar plot\n",
        "        value_counts = df_eda[feature].value_counts()\n",
        "        axes[i].bar(value_counts.index, value_counts.values)\n",
        "        axes[i].set_title(feature)\n",
        "        axes[i].set_xlabel('Категория')\n",
        "        axes[i].set_ylabel('Количество')\n",
        "        axes[i].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Удалим лишние оси\n",
        "for i in range(7, len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DJHVZI_Y0nf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 5: Подготовка данных для моделирования"
      ],
      "metadata": {
        "id": "BUJ4SVftnsgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ПОДГОТОВКА ДАННЫХ ДЛЯ МОДЕЛИРОВАНИЯ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Создаем копию данных для подготовки\n",
        "df_prepared = df[best_features].copy()\n",
        "y = df['Sleep Disorder']\n",
        "\n",
        "print(f\"Размер X: {df_prepared.shape}\")\n",
        "print(f\"Размер y: {y.shape}\")\n",
        "\n",
        "# Разделяем признаки на категориальные и числовые\n",
        "categorical_cols = df_prepared.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "numerical_cols = df_prepared.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "print(f\"\\nКатегориальные признаки ({len(categorical_cols)}): {categorical_cols}\")\n",
        "print(f\"Числовые признаки ({len(numerical_cols)}): {numerical_cols}\")\n",
        "\n",
        "# 1. Кодируем целевую переменную\n",
        "label_encoder_y = LabelEncoder()\n",
        "y_encoded = label_encoder_y.fit_transform(y)\n",
        "\n",
        "print(f\"\\nКодирование целевой переменной:\")\n",
        "for i, cls in enumerate(label_encoder_y.classes_):\n",
        "    print(f\"  {cls} -> {i}\")\n",
        "\n",
        "# 2. Подготовка признаков\n",
        "# Для категориальных признаков используем OneHotEncoding\n",
        "# Для числовых - StandardScaler\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Создаем трансформеры\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_cols),\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Применяем трансформации\n",
        "X_processed = preprocessor.fit_transform(df_prepared)\n",
        "\n",
        "# Получаем имена признаков после трансформации\n",
        "# Для OneHotEncoder\n",
        "cat_encoder = preprocessor.named_transformers_['cat']\n",
        "cat_feature_names = cat_encoder.get_feature_names_out(categorical_cols)\n",
        "\n",
        "# Объединяем имена признаков\n",
        "feature_names = list(numerical_cols) + list(cat_feature_names)\n",
        "\n",
        "print(f\"\\nПосле предобработки:\")\n",
        "print(f\"Размер X_processed: {X_processed.shape}\")\n",
        "print(f\"Количество признаков: {len(feature_names)}\")\n",
        "print(f\"\\nПервые 10 признаков: {feature_names[:10]}\")"
      ],
      "metadata": {
        "id": "hnkWOExzz4_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 6: Разделение данных на обучающую и тестовую выборки"
      ],
      "metadata": {
        "id": "fdkAuvvGlf3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"РАЗДЕЛЕНИЕ ДАННЫХ НА ОБУЧАЮЩУЮ И ТЕСТОВУЮ ВЫБОРКИ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Разделяем данные с сохранением пропорций классов\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_processed, y_encoded,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y_encoded\n",
        ")\n",
        "\n",
        "print(f\"Размеры выборок:\")\n",
        "print(f\"X_train: {X_train.shape}\")\n",
        "print(f\"X_test: {X_test.shape}\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"y_test: {y_test.shape}\")\n",
        "\n",
        "print(f\"\\nРаспределение классов в обучающей выборке:\")\n",
        "unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
        "for cls, count in zip(unique_train, counts_train):\n",
        "    cls_name = label_encoder_y.inverse_transform([cls])[0]\n",
        "    print(f\"  {cls_name} ({cls}): {count} наблюдений ({count/len(y_train)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nРаспределение классов в тестовой выборке:\")\n",
        "unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
        "for cls, count in zip(unique_test, counts_test):\n",
        "    cls_name = label_encoder_y.inverse_transform([cls])[0]\n",
        "    print(f\"  {cls_name} ({cls}): {count} наблюдений ({count/len(y_test)*100:.1f}%)\")\n"
      ],
      "metadata": {
        "id": "oNovhrMG7scC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 7: Обучение модели логистической регрессии"
      ],
      "metadata": {
        "id": "AlIRFWOFoURj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ОБУЧЕНИЕ МОДЕЛИ ЛОГИСТИЧЕСКОЙ РЕГРЕССИИ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Создаем и обучаем модель\n",
        "model = LogisticRegression(\n",
        "    multi_class='multinomial',  # Многоклассовая классификация\n",
        "    solver='lbfgs',             # Алгоритм оптимизации\n",
        "    max_iter=1000,              # Максимальное количество итераций\n",
        "    random_state=42,\n",
        "    C=1.0                       # Параметр регуляризации\n",
        ")\n",
        "\n",
        "print(\"Обучение модели...\")\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Обучение завершено!\")\n",
        "\n",
        "# Делаем предсказания\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Предсказания вероятностей (для ROC AUC)\n",
        "y_train_prob = model.predict_proba(X_train)\n",
        "y_test_prob = model.predict_proba(X_test)\n",
        "\n",
        "print(f\"\\nПараметры модели:\")\n",
        "print(f\"Классы: {model.classes_}\")\n",
        "print(f\"Коэффициенты формы: {model.coef_.shape}\")\n",
        "print(f\"Интерсепты: {model.intercept_}\")"
      ],
      "metadata": {
        "id": "rj9u4Xkd3mVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 8: Оценка качества модели"
      ],
      "metadata": {
        "id": "NyFl51K-oYJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ОЦЕНКА КАЧЕСТВА МОДЕЛИ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Функция для расчета и вывода метрик\n",
        "def evaluate_model(y_true, y_pred, y_prob=None, model_name=\"\"):\n",
        "    \"\"\"Оценка модели классификации\"\"\"\n",
        "\n",
        "    print(f\"\\n{model_name}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Базовые метрики\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"Accuracy (Точность): {accuracy:.4f}\")\n",
        "    print(f\"Precision (Точность): {precision:.4f}\")\n",
        "    print(f\"Recall (Полнота): {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "    # ROC AUC (только если есть вероятности)\n",
        "    if y_prob is not None:\n",
        "        try:\n",
        "            # Для многоклассовой классификации\n",
        "            roc_auc = roc_auc_score(y_true, y_prob, multi_class='ovr', average='weighted')\n",
        "            print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "        except:\n",
        "            print(\"ROC AUC: невозможно рассчитать\")\n",
        "\n",
        "    # Матрица ошибок\n",
        "    print(\"\\nМатрица ошибок (Confusion Matrix):\")\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(cm)\n",
        "\n",
        "    # Детальный отчет по классам\n",
        "    print(\"\\nДетальный отчет по классам:\")\n",
        "    print(classification_report(y_true, y_pred,\n",
        "                               target_names=label_encoder_y.classes_))\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "# Оценка на обучающей выборке\n",
        "print(\"\\nОЦЕНКА НА ОБУЧАЮЩЕЙ ВЫБОРКЕ:\")\n",
        "metrics_train = evaluate_model(y_train, y_train_pred, y_train_prob, \"Обучающая выборка\")\n",
        "\n",
        "# Оценка на тестовой выборке\n",
        "print(\"\\nОЦЕНКА НА ТЕСТОВОЙ ВЫБОРКЕ:\")\n",
        "metrics_test = evaluate_model(y_test, y_test_pred, y_test_prob, \"Тестовая выборка\")\n",
        "\n",
        "# Сравнение метрик\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"СРАВНЕНИЕ МЕТРИК НА ОБУЧАЮЩЕЙ И ТЕСТОВОЙ ВЫБОРКАХ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Обучающая выборка': [\n",
        "        metrics_train['accuracy'],\n",
        "        metrics_train['precision'],\n",
        "        metrics_train['recall'],\n",
        "        metrics_train['f1']\n",
        "    ],\n",
        "    'Тестовая выборка': [\n",
        "        metrics_test['accuracy'],\n",
        "        metrics_test['precision'],\n",
        "        metrics_test['recall'],\n",
        "        metrics_test['f1']\n",
        "    ],\n",
        "    'Разница': [\n",
        "        metrics_train['accuracy'] - metrics_test['accuracy'],\n",
        "        metrics_train['precision'] - metrics_test['precision'],\n",
        "        metrics_train['recall'] - metrics_test['recall'],\n",
        "        metrics_train['f1'] - metrics_test['f1']\n",
        "    ]\n",
        "}, index=['Accuracy', 'Precision', 'Recall', 'F1-Score'])\n",
        "\n",
        "print(comparison_df)\n",
        "\n",
        "# Визуализация матрицы ошибок\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Матрица ошибок для обучающей выборки\n",
        "cm_train = confusion_matrix(y_train, y_train_pred)\n",
        "sns.heatmap(cm_train, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=label_encoder_y.classes_,\n",
        "            yticklabels=label_encoder_y.classes_,\n",
        "            ax=axes[0])\n",
        "axes[0].set_title('Матрица ошибок - Обучающая выборка')\n",
        "axes[0].set_xlabel('Предсказанный класс')\n",
        "axes[0].set_ylabel('Истинный класс')\n",
        "\n",
        "# Матрица ошибок для тестовой выборки\n",
        "cm_test = confusion_matrix(y_test, y_test_pred)\n",
        "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=label_encoder_y.classes_,\n",
        "            yticklabels=label_encoder_y.classes_,\n",
        "            ax=axes[1])\n",
        "axes[1].set_title('Матрица ошибок - Тестовая выборка')\n",
        "axes[1].set_xlabel('Предсказанный класс')\n",
        "axes[1].set_ylabel('Истинный класс')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YAg71J_QLzvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 9: Анализ коэффициентов модели"
      ],
      "metadata": {
        "id": "TbrheSykrIZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"АНАЛИЗ КОЭФФИЦИЕНТОВ МОДЕЛИ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Получаем коэффициенты модели\n",
        "coefficients = model.coef_\n",
        "intercepts = model.intercept_\n",
        "\n",
        "print(f\"Форма коэффициентов: {coefficients.shape}\")\n",
        "print(f\"Количество классов: {len(model.classes_)}\")\n",
        "print(f\"Количество признаков: {coefficients.shape[1]}\")\n",
        "\n",
        "# Создаем DataFrame с коэффициентами\n",
        "coef_df = pd.DataFrame(\n",
        "    coefficients.T,\n",
        "    index=feature_names,\n",
        "    columns=[f\"Class_{cls}\" for cls in label_encoder_y.classes_]\n",
        ")\n",
        "\n",
        "print(\"\\nКоэффициенты модели для каждого класса:\")\n",
        "print(coef_df.head(10))\n",
        "\n",
        "# Визуализируем важность признаков\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "for i, cls in enumerate(label_encoder_y.classes_):\n",
        "    # Берем абсолютные значения коэффициентов для важности\n",
        "    importance = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'coefficient': coefficients[i],\n",
        "        'abs_coefficient': abs(coefficients[i])\n",
        "    })\n",
        "\n",
        "    # Сортируем по абсолютному значению\n",
        "    importance_sorted = importance.sort_values('abs_coefficient', ascending=False).head(10)\n",
        "\n",
        "    # Строим график\n",
        "    axes[i].barh(importance_sorted['feature'], importance_sorted['coefficient'])\n",
        "    axes[i].set_title(f'Важность признаков для класса: {cls}')\n",
        "    axes[i].set_xlabel('Значение коэффициента')\n",
        "    axes[i].axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
        "    axes[i].invert_yaxis()  # Самые важные сверху\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Анализируем самые важные признаки\n",
        "print(\"\\nСАМЫЕ ВАЖНЫЕ ПРИЗНАКИ ДЛЯ КАЖДОГО КЛАССА:\")\n",
        "for i, cls in enumerate(label_encoder_y.classes_):\n",
        "    print(f\"\\nКласс: {cls}\")\n",
        "\n",
        "    # Получаем коэффициенты для этого класса\n",
        "    class_coef = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'coefficient': coefficients[i]\n",
        "    })\n",
        "\n",
        "    # Сортируем по абсолютному значению\n",
        "    class_coef['abs_coef'] = abs(class_coef['coefficient'])\n",
        "    class_coef_sorted = class_coef.sort_values('abs_coef', ascending=False)\n",
        "\n",
        "    print(\"Топ-5 положительных влияний (увеличивают вероятность класса):\")\n",
        "    positive = class_coef_sorted[class_coef_sorted['coefficient'] > 0].head(5)\n",
        "    for _, row in positive.iterrows():\n",
        "        print(f\"  {row['feature']}: {row['coefficient']:.4f}\")\n",
        "\n",
        "    print(\"Топ-5 отрицательных влияний (уменьшают вероятность класса):\")\n",
        "    negative = class_coef_sorted[class_coef_sorted['coefficient'] < 0].head(5)\n",
        "    for _, row in negative.iterrows():\n",
        "        print(f\"  {row['feature']}: {row['coefficient']:.4f}\")"
      ],
      "metadata": {
        "id": "dDO8UU-0CEKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mDuzbaP8PSBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Часть 10: ROC-кривые для многоклассовой классификации"
      ],
      "metadata": {
        "id": "LoThZjn3rc3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ROC-КРИВЫЕ ДЛЯ КАЖДОГО КЛАССА\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Создаем график ROC-кривых\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Для каждого класса строим свою ROC-кривую\n",
        "for i, cls in enumerate(label_encoder_y.classes_):\n",
        "    # Бинаризуем метки для текущего класса\n",
        "    y_test_binary = (y_test == i).astype(int)\n",
        "\n",
        "    # Получаем вероятности для текущего класса\n",
        "    y_test_prob_class = y_test_prob[:, i]\n",
        "\n",
        "    # Рассчитываем ROC-кривую\n",
        "    fpr, tpr, _ = roc_curve(y_test_binary, y_test_prob_class)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # Строим кривую\n",
        "    plt.plot(fpr, tpr, label=f'{cls} (AUC = {roc_auc:.3f})')\n",
        "\n",
        "# Добавляем диагональную линию (случайный классификатор)\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Случайный классификатор (AUC = 0.5)')\n",
        "\n",
        "# Настраиваем график\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "plt.title('ROC-кривые для каждого класса')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "83O1O9XhPZRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 11: Интерпретация результатов и выводы"
      ],
      "metadata": {
        "id": "eNwwJkdlyqga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ИНТЕРПРЕТАЦИЯ РЕЗУЛЬТАТОВ И ВЫВОДЫ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Пример предсказания для новых данных\n",
        "print(\"\\nПРИМЕР ПРЕДСКАЗАНИЯ ДЛЯ НОВЫХ ДАННЫХ:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Создаем пример нового пациента\n",
        "example_patient = {\n",
        "    'Age': 42,\n",
        "    'Physical Activity Level': 45,\n",
        "    'Stress Level': 7,\n",
        "    'Heart Rate': 85,\n",
        "    'Daily Steps': 5000,\n",
        "    'BMI Category': 'Overweight',\n",
        "    'Occupation': 'Doctor'\n",
        "}\n",
        "\n",
        "# Преобразуем в DataFrame\n",
        "example_df = pd.DataFrame([example_patient])\n",
        "\n",
        "# Применяем те же трансформации\n",
        "example_processed = preprocessor.transform(example_df)\n",
        "\n",
        "# Делаем предсказание\n",
        "prediction = model.predict(example_processed)\n",
        "prediction_proba = model.predict_proba(example_processed)\n",
        "\n",
        "# Декодируем предсказание\n",
        "predicted_class = label_encoder_y.inverse_transform(prediction)[0]\n",
        "\n",
        "print(f\"\\nДанные пациента:\")\n",
        "for key, value in example_patient.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(f\"\\nПредсказание модели: {predicted_class}\")\n",
        "print(f\"\\nВероятности для каждого класса:\")\n",
        "for i, cls in enumerate(label_encoder_y.classes_):\n",
        "    print(f\"  {cls}: {prediction_proba[0][i]:.4f} ({prediction_proba[0][i]*100:.1f}%)\")\n",
        "\n",
        "# Итоговый анализ\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ИТОГОВЫЙ АНАЛИЗ МОДЕЛИ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n1. КАЧЕСТВО МОДЕЛИ:\")\n",
        "print(f\"   - Accuracy на тестовой выборке: {metrics_test['accuracy']:.4f}\")\n",
        "print(f\"   - F1-Score на тестовой выборке: {metrics_test['f1']:.4f}\")\n",
        "print(f\"   - Модель показывает {'хорошее' if metrics_test['accuracy'] > 0.7 else 'удовлетворительное' if metrics_test['accuracy'] > 0.6 else 'низкое'} качество\")\n",
        "\n",
        "print(\"\\n2. АНАЛИЗ ПЕРЕОБУЧЕНИЯ:\")\n",
        "overfitting_diff = metrics_train['accuracy'] - metrics_test['accuracy']\n",
        "print(f\"   - Разница в accuracy между train и test: {overfitting_diff:.4f}\")\n",
        "if overfitting_diff < 0.05:\n",
        "    print(\"   - Модель не показывает значительного переобучения\")\n",
        "elif overfitting_diff < 0.1:\n",
        "    print(\"   - Есть небольшое переобучение\")\n",
        "else:\n",
        "    print(\"   - Значительное переобучение, нужна регуляризация\")\n",
        "\n",
        "print(\"\\n3. ВАЖНОСТЬ ПРИЗНАКОВ:\")\n",
        "print(\"   На основе коэффициентов модели:\")\n",
        "print(\"   - Наиболее важные признаки: Age, Stress Level, Physical Activity Level\")\n",
        "print(\"   - Категориальные признаки: Occupation и BMI Category также важны\")\n",
        "\n",
        "print(\"\\n4. ПРАКТИЧЕСКОЕ ПРИМЕНЕНИЕ:\")\n",
        "print(\"   - Модель может использоваться для скрининга пациентов на расстройства сна\")\n",
        "print(\"   - Может помочь врачам в предварительной диагностике\")\n",
        "print(\"   - Позволяет выявить факторы риска развития расстройств сна\")\n",
        "\n",
        "print(\"\\n5. РЕКОМЕНДАЦИИ ПО УЛУЧШЕНИЮ:\")\n",
        "print(\"   - Собрать больше данных, особенно для классов 'Sleep Apnea' и 'Insomnia'\")\n",
        "print(\"   - Попробовать другие алгоритмы (случайный лес, градиентный бустинг)\")\n",
        "print(\"   - Использовать балансировку классов (SMOTE, oversampling)\")\n",
        "print(\"   - Настроить гиперпараметры модели (GridSearchCV)\")\n",
        "print(\"   - Добавить полиномиальные признаки или взаимодействия\")\n",
        "\n",
        "print(\"\\n6. ОГРАНИЧЕНИЯ МОДЕЛИ:\")\n",
        "print(\"   - Модель обучена на ограниченном наборе данных\")\n",
        "print(\"   - Не учитывает все возможные медицинские факторы\")\n",
        "print(\"   - Не может заменить консультацию врача\")\n",
        "print(\"   - Может иметь смещения из-за несбалансированности данных\")"
      ],
      "metadata": {
        "id": "BW-kPv8BPdKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 12: Дополнительный анализ (опционально)"
      ],
      "metadata": {
        "id": "2c1L56COz7Sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Анализ ошибок модели\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"АНАЛИЗ ОШИБОК МОДЕЛИ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Создаем DataFrame с ошибками предсказания\n",
        "errors_df = pd.DataFrame({\n",
        "    'Истинный класс': label_encoder_y.inverse_transform(y_test),\n",
        "    'Предсказанный класс': label_encoder_y.inverse_transform(y_test_pred),\n",
        "    'Вероятность предсказания': np.max(y_test_prob, axis=1)\n",
        "})\n",
        "\n",
        "# Добавляем флаг ошибки\n",
        "errors_df['Ошибка'] = errors_df['Истинный класс'] != errors_df['Предсказанный класс']\n",
        "\n",
        "print(f\"Количество ошибок: {errors_df['Ошибка'].sum()} из {len(errors_df)} ({errors_df['Ошибка'].sum()/len(errors_df)*100:.1f}%)\")\n",
        "\n",
        "# Анализируем, какие ошибки чаще всего\n",
        "print(\"\\nТипы ошибок (путаница между классами):\")\n",
        "error_crosstab = pd.crosstab(\n",
        "    errors_df[errors_df['Ошибка']]['Истинный класс'],\n",
        "    errors_df[errors_df['Ошибка']]['Предсказанный класс']\n",
        ")\n",
        "print(error_crosstab)\n",
        "\n",
        "# Анализируем уверенность модели при ошибках\n",
        "print(\"\\nСредняя уверенность модели:\")\n",
        "print(f\"При правильных предсказаниях: {errors_df[~errors_df['Ошибка']]['Вероятность предсказания'].mean():.4f}\")\n",
        "print(f\"При ошибках: {errors_df[errors_df['Ошибка']]['Вероятность предсказания'].mean():.4f}\")"
      ],
      "metadata": {
        "id": "kj_b1SeBPsTQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}