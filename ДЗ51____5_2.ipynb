{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orutkina/-./blob/main/%D0%94%D0%9751____5_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy3 gensim scikit-learn nltk # бибилотеки с которыми будем работать"
      ],
      "metadata": {
        "id": "i-C6oh7YuXjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание 5.2\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q2GrfXXruCXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт библиотек\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, silhouette_score\n",
        "\n",
        "# Загрузка датасета\n",
        "# Скачайте файл с Kaggle: https://www.kaggle.com/datasets/uom190346a/sleep-health-and-lifestyle-dataset\n",
        "df = pd.read_csv(\"Sleep_health_and_lifestyle_dataset.csv\")\n",
        "print(\"Размер датасета:\", df.shape)\n",
        "print(\"\\nПервые 5 строк:\")\n",
        "print(df.head())\n",
        "print(\"\\nИнформация о датасете:\")\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "-AVcQtfjoEcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предобработка данных"
      ],
      "metadata": {
        "id": "N-Eir46MoHlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Для датасета о сне у нас есть категориальные текстовые данные\n",
        "# Обработаем их как \"текстовые последовательности\"\n",
        "\n",
        "# Создадим текстовые последовательности из категориальных признаков\n",
        "def create_text_sequences(row):\n",
        "    \"\"\"Создание текстовой последовательности из категориальных признаков\"\"\"\n",
        "    sequence = []\n",
        "\n",
        "    # Добавляем категориальные признаки\n",
        "    if pd.notna(row['Gender']):\n",
        "        sequence.append(str(row['Gender']).lower())\n",
        "    if pd.notna(row['Occupation']):\n",
        "        # Разделяем составные профессии на отдельные слова\n",
        "        occupation_words = str(row['Occupation']).replace('_', ' ').split()\n",
        "        sequence.extend([word.lower() for word in occupation_words])\n",
        "    if pd.notna(row['BMI Category']):\n",
        "        sequence.append(str(row['BMI Category']).lower().replace(' ', '_'))\n",
        "    if pd.notna(row['Sleep Disorder']):\n",
        "        sequence.append(str(row['Sleep Disorder']).lower().replace(' ', '_'))\n",
        "\n",
        "    return sequence\n",
        "\n",
        "# Создаем текстовые последовательности для каждой строки\n",
        "text_sequences = df.apply(create_text_sequences, axis=1).tolist()\n",
        "\n",
        "print(\"Пример текстовых последовательностей:\")\n",
        "for i in range(3):\n",
        "    print(f\"Строка {i}: {text_sequences[i]}\")"
      ],
      "metadata": {
        "id": "CiveLYl1oI2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Токенизация и нормализация"
      ],
      "metadata": {
        "id": "9FAiyVRGoLSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Скачиваем стоп-слова\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "STOP_EN = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_sequence(sequence):\n",
        "    \"\"\"Предобработка текстовой последовательности\"\"\"\n",
        "    processed = []\n",
        "\n",
        "    for token in sequence:\n",
        "        # Приводим к нижнему регистру\n",
        "        token_lower = token.lower()\n",
        "\n",
        "        # Удаляем стоп-слова\n",
        "        if token_lower in STOP_EN:\n",
        "            continue\n",
        "\n",
        "        # Удаляем специальные символы (оставляем только буквы и цифры)\n",
        "        token_clean = re.sub(r'[^a-z0-9_]', '', token_lower)\n",
        "\n",
        "        if len(token_clean) > 1:  # Игнорируем слишком короткие токены\n",
        "            processed.append(token_clean)\n",
        "\n",
        "    return processed\n",
        "\n",
        "# Применяем предобработку ко всем последовательностям\n",
        "tokenized_sequences = [preprocess_sequence(seq) for seq in text_sequences]\n",
        "\n",
        "print(\"Пример токенизированных последовательностей:\")\n",
        "for i in range(3):\n",
        "    print(f\"Строка {i}: {tokenized_sequences[i]}\")"
      ],
      "metadata": {
        "id": "8Kj51o-0oOdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение модели Word2Vec"
      ],
      "metadata": {
        "id": "2TW4tbOhoPSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучаем Word2Vec на наших последовательностях\n",
        "w2v = Word2Vec(\n",
        "    sentences=tokenized_sequences,\n",
        "    vector_size=50,  # Меньший размер для меньшего датасета\n",
        "    window=3,  # Меньшее окно для коротких последовательностей\n",
        "    min_count=2,  # Слова должны встречаться минимум 2 раза\n",
        "    workers=4,\n",
        "    sg=1,  # Skip-gram\n",
        "    epochs=20,\n",
        ")\n",
        "\n",
        "# Функция для создания вектора документа\n",
        "def doc_vector(tokens, model):\n",
        "    \"\"\"Создание вектора документа из токенов\"\"\"\n",
        "    if not tokens:\n",
        "        return np.zeros(model.vector_size)\n",
        "\n",
        "    vecs = []\n",
        "    for t in tokens:\n",
        "        if t in model.wv:\n",
        "            vecs.append(model.wv[t])\n",
        "\n",
        "    if vecs:\n",
        "        return np.mean(vecs, axis=0)\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)\n",
        "\n",
        "# Создаем векторные представления для каждого наблюдения\n",
        "doc_vectors = np.vstack([doc_vector(t, w2v) for t in tokenized_sequences])\n",
        "print(f\"Размер векторов документов: {doc_vectors.shape}\")\n",
        "\n",
        "# Пример похожих слов\n",
        "print(\"\\nПримеры похожих слов в модели:\")\n",
        "try:\n",
        "    print(\"Похожие на 'engineer':\", w2v.wv.most_similar('engineer', topn=3))\n",
        "except:\n",
        "    print(\"'engineer' нет в словаре\")\n",
        "try:\n",
        "    print(\"Похожие на 'normal':\", w2v.wv.most_similar('normal', topn=3))\n",
        "except:\n",
        "    print(\"'normal' нет в словаре\")"
      ],
      "metadata": {
        "id": "wIqB8n1zoTTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обработка числовых признаков"
      ],
      "metadata": {
        "id": "pTMhefiZoVI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Выбираем числовые признаки\n",
        "numeric_cols = ['Age', 'Sleep Duration', 'Quality of Sleep',\n",
        "                'Physical Activity Level', 'Stress Level',\n",
        "                'Heart Rate', 'Daily Steps']\n",
        "\n",
        "# Извлекаем числовые данные\n",
        "numeric_data = df[numeric_cols]\n",
        "\n",
        "# Проверяем пропуски\n",
        "print(\"Пропуски в числовых данных:\")\n",
        "print(numeric_data.isnull().sum())\n",
        "\n",
        "# Обрабатываем пропуски\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "numeric_imputed = imputer.fit_transform(numeric_data)\n",
        "\n",
        "# Нормализуем числовые признаки\n",
        "scaler = StandardScaler()\n",
        "numeric_scaled = scaler.fit_transform(numeric_imputed)\n",
        "\n",
        "print(f\"Размер числовых данных после обработки: {numeric_scaled.shape}\")"
      ],
      "metadata": {
        "id": "qhC-_GNyoYh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кластеризация"
      ],
      "metadata": {
        "id": "2h08L30Iobed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Объединяем текстовые и числовые признаки\n",
        "X_features = np.hstack([doc_vectors, numeric_scaled])\n",
        "print(f\"Общий размер признаков: {X_features.shape}\")\n",
        "\n",
        "# Выбираем количество кластеров (метод локтя)\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "inertia = []\n",
        "silhouette_scores = []\n",
        "k_range = range(2, 11)\n",
        "\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(X_features)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "    if k > 1:  # Silhouette score требует минимум 2 кластера\n",
        "        silhouette_scores.append(silhouette_score(X_features, kmeans.labels_))\n",
        "    else:\n",
        "        silhouette_scores.append(0)\n",
        "\n",
        "# Визуализация метода локтя\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "ax1.plot(k_range, inertia, marker='o')\n",
        "ax1.set_xlabel('Количество кластеров')\n",
        "ax1.set_ylabel('Инерция')\n",
        "ax1.set_title('Метод локтя')\n",
        "ax1.grid(True)\n",
        "\n",
        "ax2.plot(list(k_range)[1:], silhouette_scores[1:], marker='o', color='orange')\n",
        "ax2.set_xlabel('Количество кластеров')\n",
        "ax2.set_ylabel('Silhouette Score')\n",
        "ax2.set_title('Качество кластеризации')\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Выбираем оптимальное количество кластеров (например, 3 или 4)\n",
        "optimal_k = 4  # Исходя из графика\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "df['cluster'] = kmeans.fit_predict(X_features)\n",
        "\n",
        "print(f\"Распределение по кластерам:\")\n",
        "print(df['cluster'].value_counts().sort_index())\n",
        "\n",
        "# Анализ характеристик кластеров\n",
        "cluster_stats = df.groupby('cluster')[numeric_cols].mean()\n",
        "print(\"\\nСредние значения по кластерам:\")\n",
        "print(cluster_stats)"
      ],
      "metadata": {
        "id": "zzpF5Suaod5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предсказание кластеров с помощью Decision Tree"
      ],
      "metadata": {
        "id": "AsEQ933QogPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовка данных для классификации\n",
        "X = X_features\n",
        "y = df['cluster']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# Decision Tree с подбором гиперпараметров\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    \"max_depth\": [None, 5, 10, 15],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4],\n",
        "    \"criterion\": [\"gini\", \"entropy\"],\n",
        "}\n",
        "\n",
        "grid_dt = GridSearchCV(\n",
        "    estimator=dt,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_dt.fit(X_train, y_train)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"DECISION TREE РЕЗУЛЬТАТЫ:\")\n",
        "print(\"=\" * 50)\n",
        "print(\"Лучшие параметры:\", grid_dt.best_params_)\n",
        "print(\"Лучший CV accuracy:\", round(grid_dt.best_score_, 4))\n",
        "\n",
        "best_dt = grid_dt.best_estimator_\n",
        "y_pred_dt = best_dt.predict(X_test)\n",
        "\n",
        "print(\"\\nТестовая производительность:\")\n",
        "print(\"Test accuracy:\", round(accuracy_score(y_test, y_pred_dt), 4))\n",
        "print(\"\\nОтчет по классификации:\")\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "\n",
        "# Важность признаков\n",
        "feature_names = [f\"w2v_{i}\" for i in range(doc_vectors.shape[1])] + numeric_cols\n",
        "importances = best_dt.feature_importances_\n",
        "\n",
        "# Топ-10 важных признаков\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': importances\n",
        "}).sort_values('importance', ascending=False).head(10)\n",
        "\n",
        "print(\"\\nТоп-10 важных признаков:\")\n",
        "print(importance_df)"
      ],
      "metadata": {
        "id": "P6rdTeO7oj56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предсказание кластеров с помощью KNN"
      ],
      "metadata": {
        "id": "3i4jrsb4omvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN с подбором гиперпараметров\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "param_grid_knn = {\n",
        "    \"n_neighbors\": [3, 5, 7, 9, 11],\n",
        "    \"weights\": [\"uniform\", \"distance\"],\n",
        "    \"metric\": [\"euclidean\", \"manhattan\", \"cosine\"],\n",
        "}\n",
        "\n",
        "grid_knn = GridSearchCV(\n",
        "    estimator=knn,\n",
        "    param_grid=param_grid_knn,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_knn.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"KNN РЕЗУЛЬТАТЫ:\")\n",
        "print(\"=\" * 50)\n",
        "print(\"Лучшие параметры:\", grid_knn.best_params_)\n",
        "print(\"Лучший CV accuracy:\", round(grid_knn.best_score_, 4))\n",
        "\n",
        "best_knn = grid_knn.best_estimator_\n",
        "y_pred_knn = best_knn.predict(X_test)\n",
        "\n",
        "print(\"\\nТестовая производительность:\")\n",
        "print(\"Test accuracy:\", round(accuracy_score(y_test, y_pred_knn), 4))\n",
        "print(\"\\nОтчет по классификации:\")\n",
        "print(classification_report(y_test, y_pred_knn))"
      ],
      "metadata": {
        "id": "5lurs_1NoncR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сравнение моделей и визуализация"
      ],
      "metadata": {
        "id": "HAiJk469orqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Сравнение моделей\n",
        "results = pd.DataFrame({\n",
        "    'Model': ['Decision Tree', 'KNN'],\n",
        "    'CV Accuracy': [\n",
        "        round(grid_dt.best_score_, 4),\n",
        "        round(grid_knn.best_score_, 4)\n",
        "    ],\n",
        "    'Test Accuracy': [\n",
        "        round(accuracy_score(y_test, y_pred_dt), 4),\n",
        "        round(accuracy_score(y_test, y_pred_knn), 4)\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"СРАВНЕНИЕ МОДЕЛЕЙ:\")\n",
        "print(\"=\" * 50)\n",
        "print(results)\n",
        "\n",
        "# Визуализация кластеров в 2D (PCA)\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Уменьшение размерности для визуализации\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_features)\n",
        "\n",
        "# Создаем датафрейм для визуализации\n",
        "viz_df = pd.DataFrame({\n",
        "    'PC1': X_pca[:, 0],\n",
        "    'PC2': X_pca[:, 1],\n",
        "    'cluster': df['cluster'],\n",
        "    'sleep_disorder': df['Sleep Disorder']\n",
        "})\n",
        "\n",
        "# Визуализация кластеров\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Кластеры\n",
        "scatter1 = axes[0].scatter(viz_df['PC1'], viz_df['PC2'],\n",
        "                          c=viz_df['cluster'], cmap='viridis',\n",
        "                          alpha=0.6, s=50)\n",
        "axes[0].set_xlabel('Главная компонента 1')\n",
        "axes[0].set_ylabel('Главная компонента 2')\n",
        "axes[0].set_title('Кластеризация данных (K-Means)')\n",
        "plt.colorbar(scatter1, ax=axes[0], label='Кластер')\n",
        "\n",
        "# Нарушения сна\n",
        "for disorder in viz_df['sleep_disorder'].unique():\n",
        "    subset = viz_df[viz_df['sleep_disorder'] == disorder]\n",
        "    axes[1].scatter(subset['PC1'], subset['PC2'],\n",
        "                   label=disorder, alpha=0.6, s=50)\n",
        "\n",
        "axes[1].set_xlabel('Главная компонента 1')\n",
        "axes[1].set_ylabel('Главная компонента 2')\n",
        "axes[1].set_title('Распределение нарушений сна')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Анализ кластеров\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"АНАЛИЗ КЛАСТЕРОВ:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for cluster_num in sorted(df['cluster'].unique()):\n",
        "    cluster_data = df[df['cluster'] == cluster_num]\n",
        "\n",
        "    print(f\"\\nКластер {cluster_num} ({len(cluster_data)} наблюдений):\")\n",
        "    print(f\"  Средний возраст: {cluster_data['Age'].mean():.1f}\")\n",
        "    print(f\"  Средняя продолжительность сна: {cluster_data['Sleep Duration'].mean():.1f} ч\")\n",
        "    print(f\"  Среднее качество сна: {cluster_data['Quality of Sleep'].mean():.1f}/10\")\n",
        "    print(f\"  Частота нарушений сна: {cluster_data['Sleep Disorder'].value_counts().to_dict()}\")"
      ],
      "metadata": {
        "id": "izYlZCEsos4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Основные выводы\n",
        "Адаптация подхода: Для табличных данных я преобразовал категориальные признаки (профессия, категория BMI, нарушения сна) в \"текстовые последовательности\" для обучения Word2Vec.\n",
        "\n",
        "Качество кластеризации: Использование метода локтя и silhouette score помогло определить оптимальное количество кластеров (3-4).\n",
        "\n",
        "Производительность моделей:\n",
        "\n",
        "Decision Tree показал лучшую интерпретируемость и важность признаков\n",
        "\n",
        "KNN может быть эффективнее при определенных гиперпараметрах\n",
        "\n",
        "Обе модели достигли хорошей точности предсказания кластеров\n",
        "\n",
        "Интерпретация кластеров: Каждый кластер представляет определенный \"профиль\" сна и образа жизни, что позволяет выявлять закономерности.\n",
        "\n",
        "Рекомендации для улучшения:\n",
        "\n",
        "Экспериментировать с другими алгоритмами кластеризации (DBSCAN, Gaussian Mixture)\n",
        "\n",
        "Добавить больше инженерных признаков из существующих данных\n",
        "\n",
        "Использовать ансамблевые методы для классификации\n",
        "\n",
        "Применить более продвинутые техники снижения размерности (t-SNE, UMAP)"
      ],
      "metadata": {
        "id": "vnMccmfjouzB"
      }
    }
  ]
}